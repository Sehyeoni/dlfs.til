# Chapter7 CNN convolutional neural network

## 7.1 전체 구조
CNN도 계층을 조합하여 만들 수 있으나, 합성곱 계층(convolutional layer)과 풀링 계층(pooling layer)이 새롭게 등장한다.

fully-connected 전결합 : 신경망이 인접하는 계층의 모든 뉴런과 결합되어 있음. 이 계층을 Affine 계층이라는 이름으로 구현

완전연결으로 이뤄진 네트워크의 예 :
Affine-ReLU -> Affine-ReLU -> Affine-ReLU -> Affine-ReLU -> Affine-Softmax ->

CNN으로 이뤄진 네트워크의 예 :
Conv-ReLU-Pooling -> Conv-ReLU-Pooling -> Conv-ReLU -> Affine-ReLU -> Affine-Softmax ->

pooling은 생략하기도 한다.<br>
Affine-ReLU 계층이 Conv-ReLU-(Pooling)으로 바뀌는 것

## 7.2 합성곱 계층
CNN은 각 계층 사이에 3차원 데이터같이 입체적인 데이터가 흐른다.<br
padding, stride 등 CNN고유 용어가 등장할 예정

### 7.2.1 Affine 계층의 문제점
완전연결 계층의 문제점 : 데이터를 1차원 데이터로 평탄화해야하기 때문에 데이터의 형상이 무시된다.

CNN에서의 합성곱 게층의 입출력 데이터 : feature map 특징맵. input feature map, output feature map

### 7.2.2 합성곱 연산
합성곱 연산은 이미지 처리에서 말하는 '필터 연산'에 해당함. 커널이라고 칭하기도 함

합성곱 연산은 필터의 window를 일정 간격으로 이동해가며 입력 데이터에 적용한다. (그림의 3x3부분, 크기조정가능)
![합성곱 연산의 계산 순서](fig%207-4.png)

CNN에서는 필터의 매개변수가 가중치에 해당한다. 편향도 적용함.
![합성곱 연산의 편항](fig%207-5.png)

### 7.2.3 padding, 7.2.4 stride
padding : 입력 데이터 주위를 0 패딩으로 채워 출력 크기를 조정한다.
stride : 필터를 적용하는 위치의 간격

패딩, 스트라이드, 출력 크기의 계산(출력 크기는 정수여야 함)<br>
입력 크기(H,W), 필터 크기(FW, FW), 출력 크기(OH, OW)
![패딩, 스트라이드, 출력 크기 계산](e%207.1.png)

### 7.2.5 3차원 데이터의 합성곱 연산, 7.2.6 블럭으로 생각하기, 7.2.7 배치 처리
주의할 점 : 입력 데이터의 채널 수와 필터의 채널 수가 같아야 함.
![합성곱 연산의 처리 흐름](fig%207-13.png)

## 7.3 풀링 계층
풀링 : 세로, 가로 방향의 공간을 줄이는 연산.
* max pooling(최대 풀링) : 대상 영역에서 가장 큰 원소를 꺼낸다. 이미지 인식 분야에서는 주로 최대 사용
* average pooling(평균 풀링) : 대상 영역의 원소의 평균값을 꺼낸다.

풀링 계층의 특징
* 학습해야할 매개변수가 없다.
* 채널 수가 변하지 않는다. 채널마다 독립적으로 계산한다.
* 입력의 변화에 영향을 적게 받는다. 입력 데이터가 조금 변해도 풀링의 결과는 잘 변하지 않는다.

## 7.4 합성곱/풀링 계층 구현하기, 7.5 CNN 구현하기, 7.6 CNN 시각화하기
cnn.py

### 7.7 대표적인 CNN
중요한 네트워크 2개 소개! LeNet, Alexnet

### 7.7.1 LeNet
CNN의 원조! 손글씨 숫자를 인식하는 네트워크.

현재의 CNN과 비교
- LeNet은 활성화 함수로 시그모이드를 사용하는데 현재는 주로 ReLU 사용
- LeNet은 서브샘플링을 하여 중간데이터의 크기를 줄이지만, 현재는 최대 풀링이 주류

### 7.7.2 AlexNet
딥러닝 열풍을 일으키는데 큰 역할을 한 모델
- 활성화 함수로 ReLU 이용
- Local Response Normalization LRN 이라는 국소적 정규화를 실시하는 계층 이용
- 드롭아웃 사용

LeNet과 구성 면에서 큰 차이는 없지만, GPU와 빅데이터의 발전이 딥러닝 발전의 원동력이 되었다.

## 7.8 정리
* CNN은 지금까지의 완전연결 계층 네트워크에 합성곱 계층과 풀링 계층을 새로 추가한다.
* 합성곱 계층과 풀링 계층은 im2col (이미지를 행렬로 전개하는 함수)을 이용하면 간단하고 효율적으로 구현할 수 있다.
* CNN을 시각화해보면 계층이 깊어질수록 고급 정보가 추출되는 모습을 확인할 수 있다.
* 대표적인 CNN : LeNet, AlexNet
* 딥러닝의 발전에는 빅데이터와 GPU가 크게 기여했다.


